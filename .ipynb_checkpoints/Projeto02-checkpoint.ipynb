{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Autom√°tico de Sentimento\n",
    "\n",
    "Voc√™ foi contratado por uma empresa parar analisar como os clientes est√£o reagindo a um determinado produto no Twitter. A empresa deseja que voc√™ crie um programa que ir√° analisar as mensagens dispon√≠veis e classificar√° como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mere√ßam destaque, disparem um foco de aten√ß√£o da √°rea de marketing.<br /><br />\n",
    "Como aluno de Ci√™ncia dos Dados, voc√™ lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que √© largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conte√∫do.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, voc√™ precisa implementar uma vers√£o do classificador que \"aprende\" o que √© relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Ap√≥s validado, o seu prot√≥tipo poder√° tamb√©m capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informa√ß√µes do Projeto\n",
    "\n",
    "Prazo: 13/Set at√© √†s 23:59.<br />\n",
    "Grupo: 1 ou 2 pessoas.<br /><br />\n",
    "Entreg√°veis via GitHub: \n",
    "* Arquivo notebook com o c√≥digo do classificador, seguindo as orienta√ß√µes abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**N√ÉO disponibilizar o arquivo com os *access keys/tokens* do Twitter.**\n",
    "\n",
    "\n",
    "### Check 3: \n",
    "\n",
    "At√© o dia 06 de Setembro √†s 23:59, o notebook e o xlsx devem estar no Github com as seguintes evid√™ncias: \n",
    "    * Conta no twitter criada.\n",
    "    * Produto escolhido.\n",
    "    * Arquivo Excel contendo a base de treinamento e teste j√° classificado.\n",
    "\n",
    "Sugest√£o de leitura:<br />\n",
    "http://docs.tweepy.org/en/v3.5.0/index.html<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Preparando o ambiente\n",
    "\n",
    "Instalando a biblioteca *tweepy* para realizar a conex√£o com o Twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as Bibliotecas que ser√£o utilizadas. Esteja livre para adicionar outras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "Para realizar a captura dos dados √© necess√°rio ter uma conta cadastrada no twitter:\n",
    "\n",
    "* Conta: ***@MongoStrobil***\n",
    "\n",
    "\n",
    "1. Caso ainda n√£o tenha uma: https://twitter.com/signup\n",
    "1. Depois √© necess√°rio registrar um app para usar a biblioteca: https://apps.twitter.com/\n",
    "1. Dentro do registro do App, na aba Keys and Access Tokens, anotar os seguintes campos:\n",
    "    1. Consumer Key (API Key): vtqB0NkNxZDKfQrTePLiRyibs\n",
    "    1. Consumer Secret (API Secret): RfaASnTNAEPP8V81PTtKNwLH1SzSpYXuVEiPNZMEjnu1CoOvtE\n",
    "1. Mais abaixo, gere um Token e anote tamb√©m:\n",
    "    1. Access Token: 905108217595822080GaArhSqsnTiHg0BEjJbnRdnDebVi7qx\n",
    "    1. Access Token Secret: ED7G6dt1dqHvxNgxrf5J9yFuUBoGiQ5cYNwoScFfiCe3b\n",
    "    \n",
    "1. Preencha os valores no arquivo \"auth.pass\"\n",
    "\n",
    "**ATEN√á√ÉO**: Nunca divulgue os dados desse arquivo online (GitHub, etc). Ele cont√©m as chaves necess√°rias para realizar as opera√ß√µes no twitter de forma autom√°tica e portanto √© equivalente a ser \"hackeado\". De posse desses dados, pessoas mal intencionadas podem fazer todas as opera√ß√µes manuais (tweetar, seguir, bloquear/desbloquear, listar os seguidores, etc). Para efeito do projeto, esse arquivo n√£o precisa ser entregue!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dados de autentica√ß√£o do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. N√£o modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Coletando Dados\n",
    "\n",
    "Agora vamos coletar os dados. Tenha em mente que dependendo do produto escolhido, n√£o haver√° uma quantidade significativa de mensagens, ou ainda poder haver muitos retweets.<br /><br /> \n",
    "Configurando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'game of thrones'\n",
    "\n",
    "#Quantidade m√≠nima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade m√≠nima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de l√≠ngua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documenta√ß√£o do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \n",
    "    msgs.append(msg.text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um poss√≠vel vi√©s\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo n√£o existe para n√£o substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Got = pd.read_excel(\"Game of Thrones.xlsx\", encode=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificando as Mensagens\n",
    "\n",
    "Agora voc√™ deve abrir o arquivo Excel com as mensagens capturadas e classificar na Coluna B se a mensagem √© relevante ou n√£o.<br /> \n",
    "N√£o se esque√ßa de colocar um nome para a coluna na c√©lula **B1**.<br /><br />\n",
    "Fazer o mesmo na planilha de Controle.\n",
    "\n",
    "___\n",
    "## Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Escreva o seu c√≥digo abaixo:\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. N√£o remover emojis.<br />\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positivos verdadeiros  = 69.33333333333333\n",
      "positivos falsos       = 0.6666666666666666\n",
      "negativos verdadeiros  = 27.333333333333332\n",
      "negativos falsos       = 2.6666666666666665\n",
      "{'rt': 70, 'marciorcm': 7, 'gostei': 48, 'de': 186, 'um': 63, 'v√≠deo': 51, 'youtube': 51, 'https': 143, 't.co': 143, 'wu': 1, 'y': 4, 'mmuef': 1, 'dos': 4, 'starks': 1, 'e': 38, 'seus': 1, 'significados': 1, 'game': 205, 'of': 209, 'thrones': 199, 'explicado': 1, 'gente': 3, 'cen√°rios': 1, 'reais': 2, 'que': 41, 'voc√™': 7, 'pode': 2, 'visitar': 1, 'hlllqvsy': 1, 'via': 5, 'shutterstockpt': 1, 's√©ries': 6, 'da': 27, 'hbo': 1, 'para': 12, 'ver': 10, 'antes': 1, 'do': 18, 'retorno': 1, 'rxf': 1, 'kkrh': 1, 'r': 4, 'uc': 1, 'rhrogji': 1, 'qnnodh': 1, 'eog': 1, 'gen√©tica': 1, 'nas': 2, 'fam√≠lias': 1, 'stark': 3, 'targaryen': 1, 'eu': 16, 'nao': 3, 'consigo': 1, 'comer': 1, 'ao': 5, 'mesmo': 3, 'tempo': 2, 'gfiuza_oficial': 2, 'acabou': 3, 'mas': 12, 'toda': 2, 'semana': 3, 'temos': 2, 'ana': 2, 'paula': 2, 'destronando': 2, 'geral': 2, 'os': 12, 'canastr√µes.': 2, 'rclo': 2, 'valxp': 2, 'poeticou': 4, 'o': 47, 'riso': 3, '√©': 32, 'veneno': 3, 'medo.': 3, '‚Äî': 31, 'acredito': 1, 'vou': 6, 'dizer': 4, 'isto': 1, 'come√ßar': 5, 'a': 54, 'omelete': 4, 'daenerys': 6, 'poder√°': 5, 'engravidar': 5, 'novo': 10, 'ou': 7, 'n√£o': 17, 'em': 18, 'rywnr': 1, 'm': 3, 'lh': 1, 'ewzq': 1, 'yqe': 1, 'timbeta': 1, 'betaajud‚Ä¶': 1, 'at√©': 5, 'professor': 1, 'arquitetura': 1, 'computadores': 1, 'me': 8, 'lembrando': 1, 'acabou.': 1, 'sofrimento': 1, 'vai': 2, 'durar': 1, 'mano': 1, 'tem': 4, 'ator': 1, 'q': 10, 'ribeir√£o': 1, 'preto': 1, 'lol': 1, 'papelpop': 2, 'essa': 5, 'vov√≥': 2, 'vestida': 2, 'olenna': 2, 'tyrell': 2, 'melhor': 8, 'cosplay': 3, '‚Äúgame': 2, 'thrones‚Äù': 2, 'jibs': 2, 'ljn': 2, 'sae': 2, 'uwkgy': 2, 'gv': 1, 'zpywhob√©tima': 1, 'temporada': 43, '|': 36, 'live': 29, 'mikarol': 28, 'ft': 28, 'fl√°via': 28, 'gasi': 28, 'bys': 1, 'vslx': 1, '√©tima': 3, 'escorpiao': 18, '‚Äún√£o': 24, 'podemos': 24, 'escolher': 26, 'quem': 30, 'amamos.‚Äù': 24, 'papofuradopod': 2, 'tal': 4, 'tomar': 4, 'caf√©': 3, 'manh√£': 3, 'ouvindo': 3, 'as': 6, 'teorias': 4, 'mais': 16, 'loucas': 3, 'sobre': 13, 'afinal': 3, 'white': 4, 'walkers‚Ä¶': 2, 'vvstg': 1, 'uwsj√©tima': 1, 'marquei': 2, 'como': 6, 'visto': 3, 'x': 6, 'valar': 2, 'morghulis': 2, 'qg': 3, 'wbwiinl': 1, 'bancodeseries': 3, 'assistindo': 3, 'dia': 2, 'todo': 2, 'v√≠deos': 2, 'minutos': 1, 'fico': 1, 'boas': 1, 'assistir': 6, 'uma': 20, 'h': 4, 'foi': 3, 'louco': 2, 'rachel_azeredo': 1, 'admiro': 1, 'mtoooo': 1, 'mundo': 2, 'tolkien': 1, 'criou': 1, 'leitura': 1, 'fluiu...': 1, 'agora': 3, 't√¥': 6, 'lendo': 1, 'thr‚Ä¶': 1, 'rzsmoyigma': 1, 'ri': 2, 'com': 8, 'nerdcast': 1, 'kkjkkkkkkkkkkk': 1, 'no': 8, 'fajfpduxhh': 1, 'dkvrncy': 1, 'o√©tima': 1, 'traz': 1, 'detalhes': 1, 'efeitos': 3, 'visuais': 1, 'na': 6, '¬™': 5, '‚Äògame': 1, 'thrones‚Äô': 1, 'qjcvn': 1, 'cwws': 1, 'sdv': 1, 'tfb': 1, 'quinta': 2, 'minha': 3, 'sanidade': 1, 'mental': 1, 'allef_alianca': 1, 'hoje': 5, 's√≥': 11, 'bran': 2, 'arrastada': 2, 'se': 7, 'tivesse': 1, 'cena': 1, 'triste': 1, 'doeu': 1, 'te': 1, 'fez': 1, 'ficar': 1, 'mal': 2, 'qual': 2, 'seria': 2, 'geekmigus': 1, 'coisas': 1, 'precisa': 5, 'saber': 1, 'corvo': 2, 'tr√™s': 1, 'olhos': 1, 'kytgowgzev': 1, 'sy': 1, 'gadvj': 1, 'estrela': 1, 'p': 3, 'eqlwfnai': 1, 'gau': 1, 'kba': 1, 'hp√©tima': 1, 'ilustraciones': 1, 'tarrusov': 1, 'al': 1, 'estilo': 1, 'tim': 2, 'burton': 2, 'juegodetronos': 1, 'jqr': 1, 'fg': 1, 'dgnbski': 1, 'loehdkbh': 3, 'i': 4, 'trhvdlzt': 3, 'qqorhgvmh√©tima': 1, 'vamo': 2, 'pra': 5, 'esquecer': 1, 'desse': 3, 'desastre': 1, 'simulado': 1, 's': 5, 'lytxmfps': 1, 'episode': 1, 'jon': 5, 'snow': 5, 'real': 1, 'name': 1, 'is': 2, 'revealed': 1, 'sentimento': 1, 'caralho': 2, 'amo': 1, 'mt': 4, 'letsuchoa': 1, 'gadelhalorena_': 1, 'talktomepat': 1, 'bruttrigueiro': 1, 'tavares_victor': 1, 'descubra': 1, 'dizia': 1, 'carta': 2, 'sansa': 1, 'uz': 1, 'twyh': 1, 'wrlmwty√©tima': 1, 'ela': 2, 'est√°': 5, 'tentando': 1, 'aprender': 1, 'tema': 1, 'abertura': 4, '.': 5, 'bateu': 1, 'tristeza': 1, 's√©rie': 11, 'volta': 4, 'ele': 2, 'ganhou': 1, 'copinhos': 1, 'parece': 1, 'aqueles': 1, 'pinga': 1, 'veio': 2, 'l√°': 2, 'tb': 1, 'pense': 1, 'numa': 1, 'pessoa': 3, 'feliz': 3, 'queridojeito': 1, 'mente': 2, 'livros': 3, 'espada': 2, 'pedra': 2, 'amolar': 2, 'manter': 2, 'sua': 3, 'vantagem.': 2, 'realmente': 2, 'to': 4, 'vendo': 1, 'temp': 2, 'inteira': 1, 'cada': 2, 'dias': 2, 'juicnqbgni': 1, 'trono': 1, 'ferro': 1, '‚ô•game': 1, 'thrones‚ô•': 1, 'iron': 1, 'throne': 1, 's√©tima': 6, 'video': 3, '&gt;': 1, 'rmgtwsnx': 1, 'c': 4, 'tfwavkp': 1, 'ws': 1, 'ineizzz': 1, 'boa': 3, 's√©rie.': 1, 'dei': 1, 'nesse': 2, 'tweet': 2, 'passada': 1, 'fazendo': 1, 'oq': 1, 'nnkqgijjwv': 1, 'ijnaqh': 1, 'hjs√©tima': 1, 'xkeegenwsr√©tima': 1, 'acabei': 5, 'narcos': 1, 'l√∫cifer': 2, 'preciso': 2, 'muitas': 1, 'odisseia_site': 1, 'pior': 1, 'confira': 1, 'nosso': 2, 'texto': 1, 'deixe': 1, 'opini√£o': 1, 'aqui': 4, 'xq‚Ä¶': 1, 'vc': 2, 'assiste': 2, 'tananam': 1, 'tananan': 1, 'tananammmmmm': 1, 'kkkk': 1, 'shameeeeee': 1, 'szr': 1, 'dpv': 1, '√∫nica': 1, 'coisa': 3, 'deixa': 1, 'queria': 4, 'juntamente': 1, 'meu': 4, 'namorado': 1, 'estamos': 2, 'viciados': 1, 'segunda': 2, 'nos': 1, 'julguem': 1, 't√°': 1, 'vez': 1, 'nrhl': 1, 'wdz': 1, 'walker': 1, '[official': 2, 'video]': 2, 'parte': 1, 'livro': 3, 'rola': 1, 'aquele': 1, 'di√°logo': 1, 'entre': 2, 'ned': 2, 'cersei': 1, 'claramente': 1, 'mulher': 1, 'foda': 2, 'bx': 1, 'u': 2, 'l': 1, 'he√©tima': 1, 'xwfm': 1, 'jyq√©tima': 1, 'dkmv': 1, 'nre': 1, 'chevettinho': 1, 'virilia*': 1, 'deve': 1, 'ser': 5, 'alguma': 1, 'zul': 1, 'gta': 1, 'revistamonet': 1, 'senhora': 1, 'anos': 1, 'faz': 2, 'inusitado': 1, 'cadeira': 1, 'rodas': 1, 'sucesso': 1, 'web': 1, 'lhptl‚Ä¶': 1, 'uboefr': 1, 'aw': 1, 'tramando': 1, 'contra': 1, 'n√≥s': 1, 'telltale': 2, 'gameplay': 1, 'pt': 1, 'br': 1, 'rvdeqj': 1, 'tsa√©tima': 1, 'plmattoss': 1, 'desculpem': 1, 'outras': 1, 't√©cnico': 1, 'internet': 1, 'conversando': 1, 'comigo': 1, 'aconteceu': 1, 'thrones.': 4, 'ser√°': 1, 'momento': 1, 'estar': 1, 'pr√≥xima': 2, 'patriciakogut': 4, 'luto': 4, 'prolongado': 4, 'hist√≥ria': 4, 'tv': 4, 'fhsylxgm': 3, 'eyss': 3, 'ujxx': 3, 'quero': 2, 'muito': 6, 'sweat': 1, 'ia': 1, 'algu√©m': 3, 'onde': 1, 'atores': 1, 'xruownyplp': 1, 'yuripeixoto': 1, 'loadcomics': 1, 'manda': 1, 'par√°grafos': 1, 'aleat√≥rios': 1, 'viciada': 1, 'bom': 4, 'qguiuiulla': 1, 'vcs': 1, 'a√≠': 1, 'achando': 1, 'galera': 1, 'manja': 1, 'spoilers....': 1, 'lp': 1, 'k': 2, 'ezgtu': 1, 'bkwo': 1, 'ujb': 1, 'not√≠cias': 1, 'ymc': 1, 'ilx': 1, 'guilherming': 1, 'quando': 2, 'descobres': 1, 'g': 5, 'deoutmfd': 1, 'imagens': 1, 'provam': 1, 'excelente': 1, 'anime': 1, 'yshqtqq': 1, 'vnl': 1, 'fsfecs': 1, 'liked': 1, 'rokakxpme': 1, '¬ª': 1, 'gameofthrones‚Äô': 1, 'd√°': 2, 'aos': 1, 'f√£s': 1, 'exatamente': 1, 'eles': 1, 'querem': 1, 'gots': 1, 'f': 1, 'pcljvj': 1, 'd': 4, 'ygtt': 1, 'vr': 1, 'ev': 1, 'ges_onel': 1, 'entendi': 1, 'porque': 2, 'fala': 1, 'carinha': 1, 'clipe': 1, 'the': 1, 'greatest': 1, 'entenda': 1, 'diferen√ßas': 1, 'qq': 1, 'jrmammd': 1, 'swxs': 1, 'ydefu': 1, 'rpkmszrlfr]': 1, 'julgamento': 4, 'ft.': 5, 'ricardorente': 4, 'c√©rebro': 1, 'ta': 3, 't√£o': 3, 'dominado': 1, 'por': 9, 'estudando': 1, 'parasitologia': 1, 'li': 1, 'lannister': 1, 'inv√©s': 1, 'leishmaniose': 1, 'famebowie': 1, 'sou': 3, 'lerdo': 1, 'demais': 4, 'complexa': 1, 'menos': 1, 'le‚Ä¶': 1, 'seriemaniacos': 1, 'lostiza√ß√£o': 1, 'nt': 1, 'fxx': 1, 'ymcru': 1, 'skx': 1, 'phsantos': 2, 'h√°': 2, 'vida': 2, 'al√©m': 2, 'tsshltl': 1, 'jo': 1, 'mb√©tima': 1, 'vimgnqnqb': 1, 'dbs': 1, 'xxnpz': 1, 'arya': 1, 'valonqar': 1, 'wal‚Ä¶': 1, 'syuu': 1, 'nskt': 1, 'inverno': 1, 'chegou': 3, 'definitivo': 1, 'ccg': 1, 'blizzard': 1, 'hearthstone.': 1, 'hugohrosa': 1, 'akcenrjhet': 1, 'qerv': 1, 'lbpfr√©tima': 1, 'trends': 1, 'tipo': 1, '√†': 1, 'sai': 1, 'ckhklx': 1, 'jkj': 1, 'brought': 1, 'khal': 1, 'moro': 1, 'sensacional': 1, 'vsf': 1, 'ensina': 1, 'baixar': 3, 'assisti': 1, 'ep': 3, 'tansa': 1, 'n': 1, 'sei': 1, 'tarjanerd': 1, 'ainda': 1, 'escutou': 1, 'cast': 1, 'got': 3, 'perca': 1, 'tarjacast': 1, '√©pico': 1, 'novela': 1, '‚Ä¶': 2, 'duas': 1, 'semanas': 1, 'sem': 1, 'sofro': 1, 'pfvr': 1, 'devolvam': 1, 'deus': 1, 'cara': 1, 'wlatgt': 1, 'eb': 1, 'season': 1, 'finale': 1, 'maddu': 1, 'magalh√£es': 1, 'vwdtmbliwc√©tima': 1, '‚Äì': 2, 'apresenta': 1, 'especiais': 2, 'assista': 1, 'vale': 1, 'pena': 1, 'ivofltedfa': 1, 'epis√≥dio': 7, 'bosque': 1, 'norte': 1, 'trai√ß√£o': 1, 'final': 1, 'padr√£o': 1, 'plde': 1, 'xb': 1, 'gostava': 1, 'tenha': 1, 'dito': 1, 'odiei': 1, 'aquilo': 1, 'sinto': 1, 'in√≠cio': 1, 'bosta': 2, 'dps': 1, 'melhora': 1, 'bicho': 1, 'uzpi': 1, 'mkwnt': 1, 'meets': 1, 'mance': 1, 'rayder': 1, 'qvhsu': 1, 'v': 3, 'k]': 1, 'aberta': 1, 'realdonaldtrump': 1, 'kim': 1, 'jong': 1, 'un': 1, 'favor': 1, 'comecem': 1, 'guerra': 1, 'mundial': 1, 'ap√≥s': 1, 'exibi√ß√£o': 1, 'sitevolts': 1, 'copilam': 1, 'trajet√≥ria': 1, 'fa': 1, 'aqchhpp': 1, 'vwzxuw': 1, 'tinha': 1, 'esta': 1, 'apari√ß√£o': 1, 'elen': 1, 'degeneres': 1, 'xzpuvbr': 1, 'alto': 1, 'aqui.': 1, 'saiu': 1, 'j√°': 3, 'sabem': 1, 'fazer': 2, 'n√©.': 1, 'acabando': 1, 't_t': 1, '|final': 1, 't': 1, 'jy': 1, 'pkkh': 1, 'zk': 1, 'tava': 1, 'shopping..': 1, 'nada': 2, 'come√ßa': 1, 'tocar': 1, 'm√∫sica': 1, 'deu': 1, 'vontade': 1, 'chorar': 1, 'pensar': 1, 'üòì': 1, 'bccndwj': 1, 'nova': 1, 'louca': 1, 'ysztoqfrbw√©tima': 1, 'desencaixados': 4, 'n√≠vel': 1, 'falando': 2, 'interessa': 1, 'logo': 1, 'morrendo': 1, 'saudades': 2, 'üò≠': 1, 'pvhpuuccf': 1, 'algumas': 1, 'velhas': 1, 'feridas': 1, 'nunca': 1, 'curam': 1, 'sangram': 1, 'novamente': 1, 'menor': 1, 'palavra.': 1, 'vzf': 1, 'omys': 1, 'aegons': 1, 'targaryens': 1, 'westeros': 1, 'valdir_furtado': 1, 'ate': 2, 'pesquisam': 1, 'pela': 1, 'dama': 1, 'kkk': 1, 'tu': 1, 'gosta': 2, 'tenho': 3, 'ylxjpuu': 1, 'ji': 1, 'ilsty': 1, 'gh√©tima': 1, 'wibjkf': 1, 'e√©tima': 1, 'mostra': 1, 'ex√©rcito': 1, 'mortos‚Ä¶': 1, 'kdd': 1, 'tvt': 1, 'ti': 1, 'edqt': 1, 'calango': 1, 'nem': 2, 'assisto': 1, 'acho': 3, 'musica': 1, 'nicolasmalcher': 1, 'trata': 1, '%': 1, 'esse': 2, 'c√£ozinho': 1, 'ohcehh': 1, 'ehxmmptca': 1, 'vi': 2, 'primeiro': 1, '‚ù§': 1, 'nry': 1, 'zrkkr': 1, 'vnkpdetrzy': 1, 'fosse': 1, 'bahia': 1, 'ep.': 1, 'andre_llucas': 1, 'v√£o': 1, 'apresenta√ß√µes.': 1, 'produ√ß√£o': 1, 'conteudo': 1, 'sports': 1, 'nimdrfyzxu': 1, 'desde': 1, 'nenhuma': 1, 'entendo': 1, 'gosto': 1, 'cu': 1, 'pfvr...': 1, 'kszszf': 1, 'nba√©tima': 1, 'hqn': 1, 'suiyw': 1, 'vista': 1, 'alguem': 1, 'fav√¥': 1, 'lfdo': 1, 'rcamr': 1, 'defenitivamente': 1, 'estou': 2, 'curtir': 1, 'bu√©': 1, 'rede': 1, 'neural': 1, 'escrevendo': 1, 'pr√≥ximo': 1, 'uogai': 1, 'tnl': 1, 'intelig√™nciaartificial': 1, 'amora_fachada': 1, 'ja': 2, 'jogo': 2, 'tabuleiro': 2, 'brutal': 2, 'pcj': 1, 'qidj√©': 1, 'assim': 2, 'personagens': 1, 'deveriam': 1, 'coxinha': 1, 'nerd': 1, 'breve': 1, 'coment√°rio': 1, 'atrasado': 1, '√∫ltimo': 2, 'primeira': 1, 'li√ß√£o': 1, 'dada': 1, 'que...': 1, 'rhcye': 1, 'oest': 1, 'thdswccubg': 1, 'deixou': 1, 'rei': 1, 'aerys': 1, 'descobrir': 1, 'mesma': 1, 'programa': 1, 'r√°dio': 1, 'jornalista': 1, 'sic': 1, 'daqui': 1, 'natal': 1, 'leokitsune': 1, 'fanfic': 1, 'pq': 1, 'igual': 1, 'receber': 1, 'milh√µes': 1, 'propina': 1, 'hdezavbej': 1, 'ijwzdlnrt': 1, 'muralha': 1, 'discuss√£o': 1, 'sempre': 1, 'centro': 1, 'outra': 1, 'protagonista': 1, 'sqghasqh': 1, 'w': 2, 'netflix': 1, 'hd': 1, 'aghhwrsstn': 1, 'xcyfscyke': 1, 'atribu√≠': 1, 'nota': 1, 'wbw': 1, 'gzb': 1, 'bffg': 1, 'pna': 1, 'makeover': 1, 'cadeiras': 1, 'geeks': 1, 'montandomeuap√™': 1, 'star': 1, 'wars': 1, '&amp;': 1, 'amandacaroamigo': 1, 'enquanto': 1, 'uumttagvdo': 1, 'bypye': 1, 'iats': 1, 'caso': 1, 'amor': 1, '√≥dio': 1, 'aceitando': 1, 'capa': 1, 'moto': 1, '...s√≥': 1, 'avisando': 1, 'pah': 1, 'enviar': 1, 'caixa': 1, 'postal': 1, 'kkkkkkkkkk': 1, 'cinefama': 1, 'bastidores': 2, 'wfoeupnpld': 1, 'infinitswar': 1, 'veja': 1, 'pouco': 1, 'clnsknrjn': 1, 'qkl': 1, 'wemc': 1, 'xiura': 1, 'qgs√©tima': 1, 'gameofthrones': 3, 'temproada': 1, 'ipkmw': 1, 're': 1, 'meio': 2, 'jrq': 1, 'uvo√©tima': 1, 'kc': 1, 'kjltbqe': 1, 'vs': 1, 'sandor': 1, 'clegane': 1, 'dublado': 1, 'zdni': 1, 'l]': 1, 'zmeeix': 1, 'f√©tima': 1, 'mblttezpj]': 1, 'programa√ß√£o': 1, 'inteiro': 1, 'terei': 1, 'nenhum': 1, 'rockzinho': 1, 'ent√£o': 1, 'pequeno': 1, 'almo√ßo': 1, 'continuar': 1, 'rmilh': 1, 'yv': 1, 'ie': 1, 'rooukll': 1, 'golem_': 1, 'rencontre': 1, 'rcptqfaxt': 1, 'kqymcr': 1, 'uvb': 1, 'amsjhlc': 1, 'g√™meas': 1, 'nerds': 1, 'comentar': 1, 'alvesrafa': 1, 'serie': 1, 'mds': 1, 'personagem': 1, 'sam': 1, 'oradioatividade': 1, 'cedo': 1, 'ar': 2, 'ou√ßa': 1, 'fveibbocvx': 1, 'h‚Ä¶': 1, 'versÔøΩo': 1, 'brasileira': 1, 'ai': 1, 'mtkwezo': 1, 'estalagemnerd': 1, 'drag√µes': 4, 'walkers': 1, 'intrigas': 1, 'laser': 1, 'sexo': 1, 'c‚Ä¶': 1, 'tive': 1, 'sonho': 1, 'doido': 1, 'noite': 1, 'parada': 1, 'thrones...': 1, 'sentindo': 1, '√≥rf√£o': 1, 'jr': 1, 'mud': 1, 'kbc': 1, 'wjupghjpzc': 1}\n"
     ]
    }
   ],
   "source": [
    "no_char = [\"\\n\",\":\",'\"',\"'\",'(',')',',','+','/','-','@','!','?','#','0','1','2','3','4','5','6','7','8','9','üëáüèª','ü§îü§îü§î']\n",
    "\n",
    "for e in range(0,300):\n",
    "    sub = Got.Treinamento[e]\n",
    "    for char in no_char:\n",
    "        sub = sub.replace(char, ' ')\n",
    "    sub = sub.split()\n",
    "    sub = \" \".join(sub)\n",
    "    Got.Treinamento[e] = sub\n",
    "    \n",
    "df_total = Got.Treinamento\n",
    "df_relevante = Got[Got[\"Unnamed: 1\"] == \"R\"].Treinamento\n",
    "df_irelevante = Got[Got[\"Unnamed: 1\"] == \"I\"].Treinamento\n",
    "\n",
    "lista_df = [df_total,df_relevante,df_irelevante]\n",
    "total_pal = []\n",
    "sets_pal = []\n",
    "#     username = df_total[0].split()[1]\n",
    "\n",
    "for dataf in lista_df:\n",
    "    soma_pal = 0\n",
    "    set_pal = {}\n",
    "    for tweet in dataf:\n",
    "        soma_pal += len(tweet.split()) #tweet, sem contar o nome do usuario e o \"rt\"\n",
    "\n",
    "        for palavra in tweet.split():\n",
    "            if palavra not in set_pal:\n",
    "                set_pal[palavra] = 1\n",
    "            else:\n",
    "                set_pal[palavra] += 1\n",
    "    sets_pal.append(set_pal)\n",
    "    total_pal.append(soma_pal)\n",
    "\n",
    "set_count_total = len(sets_pal[0])\n",
    "\n",
    "lista_testando = []\n",
    "for tweet in lista_df[0]:\n",
    "    prob_cond_pal_rel = 1\n",
    "    prob_cond_pal_irel = 1\n",
    "    for palavra in tweet.split():\n",
    "        try:\n",
    "            prob_cond_pal_rel = prob_cond_pal_rel*((sets_pal[1][palavra] + 1)/(total_pal[1] + set_count_total))\n",
    "        except KeyError:\n",
    "            prob_cond_pal_rel = prob_cond_pal_rel*(1/(total_pal[1] + set_count_total))\n",
    "            \n",
    "        try:\n",
    "            prob_cond_pal_irel = prob_cond_pal_irel*((sets_pal[2][palavra] + 1)/(total_pal[2] + set_count_total))\n",
    "        except KeyError:\n",
    "                prob_cond_pal_irel = prob_cond_pal_irel*(1/(total_pal[2] + set_count_total))\n",
    "    if prob_cond_pal_rel > prob_cond_pal_irel:\n",
    "        lista_testando.append(\"R\")\n",
    "    if prob_cond_pal_rel < prob_cond_pal_irel:\n",
    "        lista_testando.append(\"I\")\n",
    "\n",
    "# print(total_pal[1])\n",
    "# print(sets_pal[1][\"thrones\"])\n",
    "# print(lista_testando)\n",
    "# \" \".join(df_total[2].split())\n",
    "# df_total.split()\n",
    "\n",
    "pos_ver = 0\n",
    "pos_falso = 0\n",
    "neg_ver = 0\n",
    "neg_falso = 0\n",
    "\n",
    "# Porcentagem de positivos falsos (marcados como relevante mas n√£o s√£o relevantes)\n",
    "# Porcentagem de positivos verdadeiros (marcado como relevante e s√£o relevantes)\n",
    "# Porcentagem de negativos verdadeiros (marcado como n√£o relevante e n√£o s√£o relevantes)\n",
    "# Porcentagem de negativos falsos (marcado como n√£o relevante e s√£o relevantes)\n",
    "\n",
    "for valor in range(0,300):\n",
    "    if lista_testando[valor] == \"R\" and Got[\"Unnamed: 1\"][valor] == \"R\":\n",
    "        pos_ver += 1\n",
    "    if lista_testando[valor] == \"R\" and Got[\"Unnamed: 1\"][valor] != \"R\":\n",
    "        pos_falso += 1\n",
    "    if lista_testando[valor] != \"R\" and Got[\"Unnamed: 1\"][valor] != \"R\":\n",
    "        neg_ver += 1\n",
    "    if lista_testando[valor] != \"R\" and Got[\"Unnamed: 1\"][valor] == \"R\":\n",
    "        neg_falso += 1\n",
    "    \n",
    "print(\"positivos verdadeiros  = \" + str(pos_ver/3))\n",
    "print(\"positivos falsos       = \" + str(pos_falso/3))\n",
    "print(\"negativos verdadeiros  = \" + str(neg_ver/3))\n",
    "print(\"negativos falsos       = \" + str(neg_falso/3))\n",
    "# df_total[0].split()[2:]\n",
    "# for palavra in df_total[0].split()[2:]:\n",
    "\n",
    "print(sets_pal[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora voc√™ deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Voc√™ deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas n√£o s√£o relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e s√£o relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como n√£o relevante e n√£o s√£o relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como n√£o relevante e s√£o relevantes)\n",
    "\n",
    "Opcionalmente:\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseado na diferen√ßa de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prob(tweet):\n",
    "    prob_cond_pal_rel = 1\n",
    "    prob_cond_pal_irel = 1\n",
    "    for palavra in tweet.split():\n",
    "        try:\n",
    "            prob_cond_pal_rel = prob_cond_pal_rel*((sets_pal[1][palavra] + 1)/(total_pal[1] + set_count_total))\n",
    "        except KeyError:\n",
    "            prob_cond_pal_rel = prob_cond_pal_rel*(1/(total_pal[1] + set_count_total))\n",
    "            \n",
    "        try:\n",
    "            prob_cond_pal_irel = prob_cond_pal_irel*((sets_pal[2][palavra] + 1)/(total_pal[2] + set_count_total))\n",
    "        except KeyError:\n",
    "                prob_cond_pal_irel = prob_cond_pal_irel*(1/(total_pal[2] + set_count_total))\n",
    "    \n",
    "    if prob_cond_pal_rel > prob_cond_pal_irel:\n",
    "        print(\"Relevante\")\n",
    "    if prob_cond_pal_rel < prob_cond_pal_irel:\n",
    "        print(\"Irrelevante\")\n",
    "    return ()\n",
    "print(\"Por favor esreva algo, relevante ou nao a game of thrones:\")\n",
    "prob(input())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclus√£o.<br /> \n",
    "Fa√ßa um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como s√£o tratadas as mensagens com dupla nega√ß√£o e sarcasmo.<br />\n",
    "Proponha um plano de expans√£o. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que n√£o posso alimentar minha base de Treinamento automaticamente usando o pr√≥prio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cen√°rios de uso para o classificador Naive-Bayes. Cen√°rios sem intersec√ß√£o com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indica√ß√µes concretas de como implementar (n√£o √© preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
